{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon review scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # implement beutiful supe\n",
    "# from bs4 import BeautifulSoup as soup\n",
    "# from urllib.request import urlopen as uReq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # granola bar reviews to scrape.\n",
    "# my_url = 'https://www.amazon.com/dp/B00IZF0LCE/ref=sspa_dk_detail_0?psc=1&pd_rd_i=B00IZF0LCE&pf_rd_m=ATVPDKIKX0DER&pf_rd_p=f52e26da-1287-4616-824b-efc564ff75a4&pf_rd_r=Z5YVK618HXM9MS3AJ4EE&pd_rd_wg=Wvcz4&pf_rd_s=desktop-dp-sims&pf_rd_t=40701&pd_rd_w=VphJd&pf_rd_i=desktop-dp-sims&pd_rd_r=8ff32237-bcf7-11e8-b3a9-1f5f95d9d540#customerReviews'\n",
    "# uClient = uReq(my_url)\n",
    "# page_html = uClient.read()\n",
    "# uClient.close()\n",
    "\n",
    "# page_soup = soup(page_html, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# containers = page_soup.findAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from lxml import html  \n",
    "import json\n",
    "import requests\n",
    "import json,re\n",
    "from dateutil import parser as dateparser\n",
    "from time import sleep\n",
    "\n",
    "def ParseReviews(asin):\n",
    "    # for i in range(5):\n",
    "    # \ttry:\n",
    "    #This script has only been tested with Amazon.com\n",
    "    amazon_url  = 'http://www.amazon.com/dp/'+asin\n",
    "#     print(amazon_url)\n",
    "    # Add some recent user agent to prevent amazon from blocking the request \n",
    "    # Find some chrome user agent strings  here https://udger.com/resources/ua-list/browser-detail?browser=Chrome\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36'}\n",
    "    page = requests.get(amazon_url,headers = headers,verify=False)\n",
    "    page_response = page.text\n",
    "#     print(page_response)\n",
    "    f = open(\"pageText.txt\", \"w\")\n",
    "    f.write(page_response)\n",
    "    f.close() \n",
    "\n",
    "    parser = html.fromstring(page_response)\n",
    "\n",
    "    XPATH_AGGREGATE = '//span[@id=\"acrCustomerReviewText\"]'\n",
    "    XPATH_REVIEW_SECTION_1 = '//div[contains(@id,\"reviews-summary\")]'\n",
    "#     XPATH_REVIEW_SECTION_2 = '///div[@data-hook=\"review\"]'\n",
    "#     XPATH_REVIEW_SECTION_2 = '//div[@data-hook=\"review-body\"]'\n",
    "//*[@id=\"customer_review-R1P9WR9QZB3PSQ\"]/div[4]/span\n",
    "    XPATH_REVIEW_SECTION_2 = '//*[@id=\"customer_review-*\"]/div[4]/span'\n",
    "\n",
    "\n",
    "    \n",
    "    XPATH_AGGREGATE_RATING = '//table[@id=\"histogramTable\"]//tr'\n",
    "    XPATH_PRODUCT_NAME = '//h1//span[@id=\"productTitle\"]//text()'\n",
    "    XPATH_PRODUCT_PRICE  = '//span[@id=\"priceblock_ourprice\"]/text()'\n",
    "    \n",
    "    raw_product_price = parser.xpath(XPATH_PRODUCT_PRICE)\n",
    "    print(raw_product_price)\n",
    "    product_price = ''.join(raw_product_price).replace(',','')\n",
    "\n",
    "    raw_product_name = parser.xpath(XPATH_PRODUCT_NAME)\n",
    "    product_name = ''.join(raw_product_name).strip()\n",
    "    print(product_name)\n",
    "    total_ratings  = parser.xpath(XPATH_AGGREGATE_RATING)\n",
    "    testRev = parser.xpath(XPATH_REVIEW_SECTION_2)\n",
    "    print('This is test reviews', testRev)\n",
    "    reviews = parser.xpath(XPATH_REVIEW_SECTION_1)\n",
    "#     print(reviews)\n",
    "    if not reviews:\n",
    "        reviews = parser.xpath(XPATH_REVIEW_SECTION_2)\n",
    "    ratings_dict = {}\n",
    "    reviews_list = []\n",
    "    \n",
    "    if not reviews:\n",
    "        raise ValueError('unable to find reviews in page')\n",
    "\n",
    "    #grabing the rating  section in product page\n",
    "    for ratings in total_ratings:\n",
    "        extracted_rating = ratings.xpath('./td//a//text()')\n",
    "        if extracted_rating:\n",
    "            rating_key = extracted_rating[0] \n",
    "            raw_raing_value = extracted_rating[1]\n",
    "            rating_value = raw_raing_value\n",
    "            if rating_key:\n",
    "                ratings_dict.update({rating_key:rating_value})\n",
    "                \n",
    "    #Parsing individual reviews\n",
    "    for review in reviews:\n",
    "        XPATH_RATING  = './/i[@data-hook=\"review-star-rating\"]//text()'\n",
    "        XPATH_REVIEW_HEADER = './/a[@data-hook=\"review-title\"]//text()'\n",
    "        XPATH_REVIEW_POSTED_DATE = './/span[@data-hook=\"review-date\"]//text()'\n",
    "        XPATH_REVIEW_TEXT_1 = './/div[@data-hook=\"review-collapsed\"]//text()'\n",
    "        XPATH_REVIEW_TEXT_2 = './/div//span[@data-action=\"columnbalancing-showfullreview\"]/@data-columnbalancing-showfullreview'\n",
    "        XPATH_REVIEW_COMMENTS = './/span[@data-hook=\"review-comment\"]//text()'\n",
    "        XPATH_AUTHOR  = './/span[contains(@class,\"profile-name\")]//text()'\n",
    "        XPATH_REVIEW_TEXT_3  = './/div[contains(@id,\"dpReviews\")]/div/text()'\n",
    "\n",
    "        raw_review_author = review.xpath(XPATH_AUTHOR)\n",
    "        raw_review_rating = review.xpath(XPATH_RATING)\n",
    "        raw_review_header = review.xpath(XPATH_REVIEW_HEADER)\n",
    "        raw_review_posted_date = review.xpath(XPATH_REVIEW_POSTED_DATE)\n",
    "        raw_review_text1 = review.xpath(XPATH_REVIEW_TEXT_1)\n",
    "        raw_review_text2 = review.xpath(XPATH_REVIEW_TEXT_2)\n",
    "        raw_review_text3 = review.xpath(XPATH_REVIEW_TEXT_3)\n",
    "\n",
    "        #cleaning data\n",
    "        author = ' '.join(' '.join(raw_review_author).split())\n",
    "        review_rating = ''.join(raw_review_rating).replace('out of 5 stars','')\n",
    "        review_header = ' '.join(' '.join(raw_review_header).split())\n",
    "        \n",
    "        try:\n",
    "            review_posted_date = dateparser.parse(''.join(raw_review_posted_date)).strftime('%d %b %Y')\n",
    "        except:\n",
    "            review_posted_date = None\n",
    "        review_text = ' '.join(' '.join(raw_review_text1).split())\n",
    "\n",
    "        #grabbing hidden comments if present\n",
    "        if raw_review_text2:\n",
    "            json_loaded_review_data = json.loads(raw_review_text2[0])\n",
    "            json_loaded_review_data_text = json_loaded_review_data['rest']\n",
    "            cleaned_json_loaded_review_data_text = re.sub('<.*?>','',json_loaded_review_data_text)\n",
    "            full_review_text = review_text+cleaned_json_loaded_review_data_text\n",
    "        else:\n",
    "            full_review_text = review_text\n",
    "        if not raw_review_text1:\n",
    "            full_review_text = ' '.join(' '.join(raw_review_text3).split())\n",
    "\n",
    "        raw_review_comments = review.xpath(XPATH_REVIEW_COMMENTS)\n",
    "        review_comments = ''.join(raw_review_comments)\n",
    "        review_comments = re.sub('[A-Za-z]','',review_comments).strip()\n",
    "        review_dict = {\n",
    "                            'review_comment_count':review_comments,\n",
    "                            'review_text':full_review_text,\n",
    "                            'review_posted_date':review_posted_date,\n",
    "                            'review_header':review_header,\n",
    "                            'review_rating':review_rating,\n",
    "                            'review_author':author\n",
    "\n",
    "                        }\n",
    "        reviews_list.append(review_dict)\n",
    "    data = {\n",
    "                'ratings':ratings_dict,\n",
    "                'reviews':reviews_list,\n",
    "                'url':amazon_url,\n",
    "                'price':product_price,\n",
    "                'name':product_name\n",
    "            }\n",
    "    return data\n",
    "    #  except ValueError:\n",
    "    # \t\tprint(\"Retrying to get the correct response\")\n",
    "\n",
    "    # return {\"error\":\"failed to process the page\",\"asin\":asin}\n",
    "\n",
    "def ReadAsin():\n",
    "    #Add your own ASINs here \n",
    "    AsinList = ['B01ETPUQ6E','B017HW9DEW']\n",
    "    extracted_data = []\n",
    "    for asin in AsinList:\n",
    "        print(\"Downloading and processing page http://www.amazon.com/dp/\"+asin)\n",
    "        extracted_data.append(ParseReviews(asin))\n",
    "        sleep(5)\n",
    "    f = open('data.json','w')\n",
    "    json.dump(extracted_data,f,indent=4)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# \tReadAsin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lorinfields/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Samsung Galaxy J7 - No Contract Phone - White - (Boost Mobile)(Carrier locked phone)\n",
      "This is test reviews []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unable to find reviews in page",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-18606a872f42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataPack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParseReviews\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'B01ETPUQ6E'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-f5c5badd2a71>\u001b[0m in \u001b[0;36mParseReviews\u001b[0;34m(asin)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unable to find reviews in page'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m#grabing the rating  section in product page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unable to find reviews in page"
     ]
    }
   ],
   "source": [
    "dataPack = ParseReviews('B01ETPUQ6E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html  \n",
    "import json\n",
    "import requests\n",
    "import json,re\n",
    "from dateutil import parser as dateparser\n",
    "from time import sleep\n",
    "\n",
    "def ParseReviews(asin):\n",
    "\t# for i in range(5):\n",
    "\t# \ttry:\n",
    "\t#This script has only been tested with Amazon.com\n",
    "\tamazon_url  = 'http://www.amazon.com/dp/'+asin\n",
    "\t# Add some recent user agent to prevent amazon from blocking the request \n",
    "\t# Find some chrome user agent strings  here https://udger.com/resources/ua-list/browser-detail?browser=Chrome\n",
    "\theaders = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36'}\n",
    "\tpage = requests.get(amazon_url,headers = headers,verify=False)\n",
    "\tpage_response = page.text\n",
    "\n",
    "\tparser = html.fromstring(page_response)\n",
    "\tXPATH_AGGREGATE = '//span[@id=\"acrCustomerReviewText\"]'\n",
    "\tXPATH_REVIEW_SECTION_1 = '//div[contains(@id,\"reviews-summary\")]'\n",
    "\tXPATH_REVIEW_SECTION_2 = '//div[@data-hook=\"review\"]'\n",
    "\n",
    "\tXPATH_AGGREGATE_RATING = '//table[@id=\"histogramTable\"]//tr'\n",
    "\tXPATH_PRODUCT_NAME = '//h1//span[@id=\"productTitle\"]//text()'\n",
    "\tXPATH_PRODUCT_PRICE  = '//span[@id=\"priceblock_ourprice\"]/text()'\n",
    "\t\n",
    "\traw_product_price = parser.xpath(XPATH_PRODUCT_PRICE)\n",
    "\tproduct_price = ''.join(raw_product_price).replace(',','')\n",
    "\n",
    "\traw_product_name = parser.xpath(XPATH_PRODUCT_NAME)\n",
    "\tproduct_name = ''.join(raw_product_name).strip()\n",
    "\ttotal_ratings  = parser.xpath(XPATH_AGGREGATE_RATING)\n",
    "\treviews = parser.xpath(XPATH_REVIEW_SECTION_1)\n",
    "\tif not reviews:\n",
    "\t\treviews = parser.xpath(XPATH_REVIEW_SECTION_2)\n",
    "\tratings_dict = {}\n",
    "\treviews_list = []\n",
    "\t\n",
    "\tif not reviews:\n",
    "\t\traise ValueError('unable to find reviews in page')\n",
    "\n",
    "\t#grabing the rating  section in product page\n",
    "\tfor ratings in total_ratings:\n",
    "\t\textracted_rating = ratings.xpath('./td//a//text()')\n",
    "\t\tif extracted_rating:\n",
    "\t\t\trating_key = extracted_rating[0] \n",
    "\t\t\traw_raing_value = extracted_rating[1]\n",
    "\t\t\trating_value = raw_raing_value\n",
    "\t\t\tif rating_key:\n",
    "\t\t\t\tratings_dict.update({rating_key:rating_value})\n",
    "\t\n",
    "\t#Parsing individual reviews\n",
    "\tfor review in reviews:\n",
    "\t\tXPATH_RATING  = './/i[@data-hook=\"review-star-rating\"]//text()'\n",
    "\t\tXPATH_REVIEW_HEADER = './/a[@data-hook=\"review-title\"]//text()'\n",
    "\t\tXPATH_REVIEW_POSTED_DATE = './/span[@data-hook=\"review-date\"]//text()'\n",
    "\t\tXPATH_REVIEW_TEXT_1 = './/div[@data-hook=\"review-collapsed\"]//text()'\n",
    "\t\tXPATH_REVIEW_TEXT_2 = './/div//span[@data-action=\"columnbalancing-showfullreview\"]/@data-columnbalancing-showfullreview'\n",
    "\t\tXPATH_REVIEW_COMMENTS = './/span[@data-hook=\"review-comment\"]//text()'\n",
    "\t\tXPATH_AUTHOR  = './/span[contains(@class,\"profile-name\")]//text()'\n",
    "\t\tXPATH_REVIEW_TEXT_3  = './/div[contains(@id,\"dpReviews\")]/div/text()'\n",
    "\t\t\n",
    "\t\traw_review_author = review.xpath(XPATH_AUTHOR)\n",
    "\t\traw_review_rating = review.xpath(XPATH_RATING)\n",
    "\t\traw_review_header = review.xpath(XPATH_REVIEW_HEADER)\n",
    "\t\traw_review_posted_date = review.xpath(XPATH_REVIEW_POSTED_DATE)\n",
    "\t\traw_review_text1 = review.xpath(XPATH_REVIEW_TEXT_1)\n",
    "\t\traw_review_text2 = review.xpath(XPATH_REVIEW_TEXT_2)\n",
    "\t\traw_review_text3 = review.xpath(XPATH_REVIEW_TEXT_3)\n",
    "\n",
    "\t\t#cleaning data\n",
    "\t\tauthor = ' '.join(' '.join(raw_review_author).split())\n",
    "\t\treview_rating = ''.join(raw_review_rating).replace('out of 5 stars','')\n",
    "\t\treview_header = ' '.join(' '.join(raw_review_header).split())\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\treview_posted_date = dateparser.parse(''.join(raw_review_posted_date)).strftime('%d %b %Y')\n",
    "\t\texcept:\n",
    "\t\t\treview_posted_date = None\n",
    "\t\treview_text = ' '.join(' '.join(raw_review_text1).split())\n",
    "\n",
    "\t\t#grabbing hidden comments if present\n",
    "\t\tif raw_review_text2:\n",
    "\t\t\tjson_loaded_review_data = json.loads(raw_review_text2[0])\n",
    "\t\t\tjson_loaded_review_data_text = json_loaded_review_data['rest']\n",
    "\t\t\tcleaned_json_loaded_review_data_text = re.sub('<.*?>','',json_loaded_review_data_text)\n",
    "\t\t\tfull_review_text = review_text+cleaned_json_loaded_review_data_text\n",
    "\t\telse:\n",
    "\t\t\tfull_review_text = review_text\n",
    "\t\tif not raw_review_text1:\n",
    "\t\t\tfull_review_text = ' '.join(' '.join(raw_review_text3).split())\n",
    "\n",
    "\t\traw_review_comments = review.xpath(XPATH_REVIEW_COMMENTS)\n",
    "\t\treview_comments = ''.join(raw_review_comments)\n",
    "\t\treview_comments = re.sub('[A-Za-z]','',review_comments).strip()\n",
    "\t\treview_dict = {\n",
    "\t\t\t\t\t\t\t'review_comment_count':review_comments,\n",
    "\t\t\t\t\t\t\t'review_text':full_review_text,\n",
    "\t\t\t\t\t\t\t'review_posted_date':review_posted_date,\n",
    "\t\t\t\t\t\t\t'review_header':review_header,\n",
    "\t\t\t\t\t\t\t'review_rating':review_rating,\n",
    "\t\t\t\t\t\t\t'review_author':author\n",
    "\n",
    "\t\t\t\t\t\t}\n",
    "\t\treviews_list.append(review_dict)\n",
    "\n",
    "\tdata = {\n",
    "\t\t\t\t'ratings':ratings_dict,\n",
    "\t\t\t\t'reviews':reviews_list,\n",
    "\t\t\t\t'url':amazon_url,\n",
    "\t\t\t\t'price':product_price,\n",
    "\t\t\t\t'name':product_name\n",
    "\t\t\t}\n",
    "\treturn data\n",
    "\t# \texcept ValueError:\n",
    "\t# \t\tprint(\"Retrying to get the correct response\")\n",
    "\n",
    "\t# return {\"error\":\"failed to process the page\",\"asin\":asin}\n",
    "\t\t\t\n",
    "def ReadAsin():\n",
    "\t#Add your own ASINs here \n",
    "\tAsinList = ['B01ETPUQ6E','B017HW9DEW']\n",
    "\textracted_data = []\n",
    "\tfor asin in AsinList:\n",
    "\t\tprint(\"Downloading and processing page http://www.amazon.com/dp/\"+asin)\n",
    "\t\textracted_data.append(ParseReviews(asin))\n",
    "\t\tsleep(5)\n",
    "\tf = open('data.json','w')\n",
    "\tjson.dump(extracted_data,f,indent=4)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tReadAsin()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
