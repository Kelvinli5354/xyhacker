{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "\n",
    "# If it gives you an error of saying there is no 'main' attribute, try updating your pip\n",
    "\n",
    "pip.main(['install','gender-guesser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('reviews_Grocery_and_Gourmet_Food.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de = df[['reviewerName', 'reviewText', 'summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = de.rename(index=str, columns={\"reviewerName\": \"names\", \"reviewText\": \"review\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Guesser (only accepts names with the first letter capitalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gender_guesser.detector as gender\n",
    "d = gender.Detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the First names of each username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_names = []\n",
    "\n",
    "for i in range(0,1289857):\n",
    "    name = str(data['names'].values[i]).split(' ', 1)[0]\n",
    "    first_names.append(name)\n",
    "    \n",
    "first_names = [k.lower() for k in first_names]         # lowercase everything\n",
    "first_names = [i.capitalize() for i in first_names]    # capitalize the first letter of every name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the genders thru gender guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "genders = []\n",
    "\n",
    "for i in first_names[0:len(first_names)]:\n",
    "    if d.get_gender(i) == 'male':\n",
    "        genders.append('male')\n",
    "    elif d.get_gender(i) == 'female':\n",
    "        genders.append('female')\n",
    "    else:\n",
    "        genders.append('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_series = pd.Series(genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['gender'] = genders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset to pickle\n",
    "\n",
    "**The names that were classified with a gender are appended accordingly**\n",
    "\n",
    "**The rest of the unknowns will have to be classified through the help of the SSA dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle('data_remastered_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in First names from the SSA(Social Security Administration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list = pd.read_excel('https://query.data.world/s/gfpluqi43bpbtqlraona72ozmzo6yo')\n",
    "\n",
    "name_gen = name_list[['Name','Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_gen.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_list = name_gen['Name'].str.lower().values                                  # lower case all the values\n",
    "\n",
    "female_names = name_gen.loc[name_gen['Gender'] == 'F'].reset_index(drop = True)   # gather a female list\n",
    "\n",
    "male_names = name_gen.loc[name_gen['Gender'] == 'M'].reset_index(drop = True)     # gather a male list\n",
    "\n",
    "female_list = list(female_names['Name'].str.lower().values)\n",
    "\n",
    "male_list = list(male_names['Name'].str.lower().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('males: ',len(male_list))\n",
    "print('female: ', len(female_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we start gathering the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data = gender_data[gender_data.names.str.contains(\"Nguyen\") == False]  # remove all the Nguyens because the name's vague"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering all the unknkowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknowns = gender_data.loc[gender_data['gender'] == 'unknown']\n",
    "\n",
    "unknown_names = unknowns['names'].str.lower().values\n",
    "\n",
    "unknown_list = list(unknown_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing  names that I deemed to be too vague or unnecessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_list.remove('mi')\n",
    "female_list.remove('brynn')\n",
    "female_list.remove('jada')\n",
    "female_list.remove('nyla')\n",
    "female_list.remove('rowan')\n",
    "female_list.remove('lia')\n",
    "female_list.remove('sloane')\n",
    "female_list.remove('ryan')\n",
    "female_list.remove('willa')\n",
    "female_list.remove('itzel')\n",
    "female_list.remove('cameron')\n",
    "female_list.remove('imani')\n",
    "female_list.remove('charli')\n",
    "female_list.remove('liberty')\n",
    "female_list.remove('guadalupe')\n",
    "female_list.remove('shiloh')\n",
    "female_list.remove('remington')\n",
    "female_list.remove('amani')\n",
    "female_list.remove('lea')\n",
    "female_list.remove('amia')\n",
    "female_list.remove('noor')\n",
    "female_list.remove('frankie')\n",
    "female_list.remove('stevie')\n",
    "female_list.remove('danny')\n",
    "female_list.remove('anny')\n",
    "female_list.remove('an')\n",
    "female_list.remove('ann')\n",
    "female_list.remove('island')\n",
    "female_list.remove('vladislava')\n",
    "female_list.remove('islah')\n",
    "female_list.remove('islay')\n",
    "female_list.remove('aisla')\n",
    "female_list.remove('isla')\n",
    "female_list.remove('campbell')\n",
    "female_list.remove('emerleigh')\n",
    "female_list.remove('emerlee')\n",
    "female_list.remove('miller')\n",
    "female_list.remove('love')\n",
    "female_list.remove('lovely')\n",
    "female_list.remove('mylove')\n",
    "female_list.remove('clover')\n",
    "female_list.remove('tran')\n",
    "female_list.remove('trany')\n",
    "female_list.remove('traniya')\n",
    "female_list.remove('lexi')\n",
    "female_list.remove('alex')\n",
    "female_list.remove('alexander')\n",
    "female_list.remove('alexei')\n",
    "female_list.remove('alexiah')\n",
    "female_list.remove('dalexa')\n",
    "female_list.remove('alexus')\n",
    "female_list.remove('alexza')\n",
    "female_list.remove('jalexis')\n",
    "female_list.remove('alexxis')\n",
    "female_list.remove('jalexia')\n",
    "female_list.remove('alexx')\n",
    "female_list.remove('alexius')\n",
    "female_list.remove('alexsis')\n",
    "female_list.remove('yalexa')\n",
    "female_list.remove('jalexa')\n",
    "female_list.remove('yuchen')\n",
    "female_list.remove('yichen')\n",
    "female_list.remove('fara')\n",
    "female_list.remove('sophy') #too many meaning\n",
    "female_list.remove('dalis')\n",
    "female_list.remove('alis')\n",
    "female_list.remove('samaa')\n",
    "female_list.remove('sama')\n",
    "female_list.remove('sami')\n",
    "female_list.remove('dutchess')\n",
    "female_list.remove('gene')\n",
    "female_list.remove('imogene')\n",
    "female_list.remove('nation')\n",
    "female_list.remove('tsion')\n",
    "female_list.remove('passion')\n",
    "female_list.remove('myers')\n",
    "female_list.remove('cedar')\n",
    "female_list.remove('chance')\n",
    "female_list.remove('nature')\n",
    "female_list.remove('asher')\n",
    "female_list.remove('tate')\n",
    "female_list.remove('tatem')\n",
    "female_list.remove('ronia')\n",
    "female_list.remove('roni')\n",
    "female_list.remove('ronin')\n",
    "female_list.remove('roniyah')\n",
    "female_list.remove('olena')\n",
    "female_list.remove('soledad')\n",
    "female_list.remove('solei')\n",
    "female_list.remove('soley')\n",
    "female_list.remove('sole')\n",
    "female_list.remove('solena')\n",
    "female_list.remove('soleigh')\n",
    "female_list.remove('solene')\n",
    "female_list.remove('soleil')\n",
    "female_list.remove('sunshine')\n",
    "female_list.remove('shine')\n",
    "female_list.remove('taline')\n",
    "female_list.remove('vitalia')\n",
    "female_list.remove('italie')\n",
    "female_list.remove('atalie')\n",
    "female_list.remove('tali')\n",
    "female_list.remove('talin')\n",
    "female_list.remove('talisa')\n",
    "female_list.remove('catalia')\n",
    "female_list.remove('talisha')\n",
    "female_list.remove('itali')\n",
    "female_list.remove('italia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_list.remove('ashley') # 98% of the time, a girl name\n",
    "male_list.remove('campbell') # 100% of the time, is a last name\n",
    "male_list.remove('camp')   # only 44 people in the US database with this name\n",
    "male_list.remove('able')\n",
    "male_list.remove('cable')\n",
    "male_list.remove('kable')\n",
    "male_list.remove('gable')\n",
    "male_list.remove('merle')\n",
    "male_list.remove('miller') # 100% of the time, is a last name\n",
    "male_list.remove('rien')\n",
    "male_list.remove('love') # too many usage that's not a name\n",
    "male_list.remove('lovell') # only .0007% has this as first name\n",
    "male_list.remove('emma')  # over 95% are girls with this name\n",
    "male_list.remove('macai')\n",
    "male_list.remove('macaiah')\n",
    "male_list.remove('erin')  # a majority of erin's are female\n",
    "male_list.remove('katherine')\n",
    "male_list.remove('flex') \n",
    "male_list.remove('chen') # 100% sure chen is a last name\n",
    "male_list.remove('yicheng')\n",
    "male_list.remove('yichen')\n",
    "male_list.remove('haochen')\n",
    "male_list.remove('chengyu')\n",
    "male_list.remove('berl')\n",
    "male_list.remove('kimberly')\n",
    "male_list.remove('kimber')\n",
    "male_list.remove('kitt')\n",
    "male_list.remove('kris')  # more females named kris\n",
    "male_list.remove('kristan')\n",
    "male_list.remove('krishna')\n",
    "male_list.remove('krish')\n",
    "male_list.remove('akrish')\n",
    "male_list.remove('krishiv')\n",
    "male_list.remove('kaceon')\n",
    "male_list.remove('kalyn')\n",
    "male_list.remove('shaka')\n",
    "male_list.remove('kaecyn')\n",
    "male_list.remove('mieko')\n",
    "male_list.remove('kade')\n",
    "male_list.remove('khysen')\n",
    "male_list.remove('khang')\n",
    "male_list.remove('makiah')\n",
    "male_list.remove('kayo')\n",
    "male_list.remove('kweli')\n",
    "male_list.remove('miking')\n",
    "male_list.remove('kilyan')\n",
    "male_list.remove('hawken')\n",
    "male_list.remove('oaklyn')\n",
    "male_list.remove('kord')\n",
    "male_list.remove('kali')\n",
    "male_list.remove('ikher')\n",
    "male_list.remove('iokepa')\n",
    "male_list.remove('kage')\n",
    "male_list.remove('kinzler')\n",
    "male_list.remove('kale')\n",
    "male_list.remove('malak')\n",
    "male_list.remove('kota')\n",
    "male_list.remove('tank')\n",
    "male_list.remove('anker')\n",
    "male_list.remove('kalen')\n",
    "male_list.remove('maika')\n",
    "male_list.remove('kristen')\n",
    "male_list.remove('lucky')\n",
    "male_list.remove('eker')\n",
    "male_list.remove('yuki')\n",
    "male_list.remove('akai')\n",
    "male_list.remove('tyke')\n",
    "male_list.remove('karan')\n",
    "male_list.remove('park')\n",
    "male_list.remove('aiken')\n",
    "male_list.remove('mackinley')\n",
    "male_list.remove('karma')\n",
    "male_list.remove('lakeland')\n",
    "male_list.remove('kortland')\n",
    "male_list.remove('mika')\n",
    "male_list.remove('kari')\n",
    "male_list.remove('kees')\n",
    "male_list.remove('kori')\n",
    "male_list.remove('rockwell')\n",
    "male_list.remove('miiking')\n",
    "male_list.remove('kash')\n",
    "male_list.remove('huckleberry')\n",
    "male_list.remove('eiker')\n",
    "male_list.remove('anik')\n",
    "male_list.remove('kole')\n",
    "male_list.remove('kona')\n",
    "male_list.remove('izek')\n",
    "male_list.remove('kail')\n",
    "male_list.remove('tyking')\n",
    "male_list.remove('kimi')\n",
    "male_list.remove('oaks')\n",
    "male_list.remove('kato')\n",
    "male_list.remove('kell')\n",
    "male_list.remove('hawk')\n",
    "male_list.remove('york')\n",
    "male_list.remove('beck')\n",
    "male_list.remove('kashe')\n",
    "male_list.remove('koda')\n",
    "male_list.remove('kree')\n",
    "male_list.remove('vonn')\n",
    "male_list.remove('ivon')\n",
    "male_list.remove('novah')\n",
    "male_list.remove('nova')\n",
    "male_list.remove('novak')\n",
    "male_list.remove('casanova')\n",
    "male_list.remove('moon')\n",
    "male_list.remove('grace')\n",
    "male_list.remove('gracen')\n",
    "male_list.remove('graceson')\n",
    "male_list.remove('trace')\n",
    "male_list.remove('race')\n",
    "male_list.remove('racer')\n",
    "male_list.remove('todd') #uncommon name\n",
    "male_list.remove('manhattan')\n",
    "male_list.remove('hattan')\n",
    "male_list.remove('wolf')\n",
    "male_list.remove('wolfgang')\n",
    "male_list.remove('wolfe')\n",
    "male_list.remove('wolfram')\n",
    "male_list.remove('dutch')\n",
    "male_list.remove('myer')\n",
    "male_list.remove('myers')\n",
    "male_list.remove('gene')\n",
    "male_list.remove('genesis')\n",
    "male_list.remove('tionne')\n",
    "male_list.remove('tion')\n",
    "male_list.remove('nation')\n",
    "male_list.remove('sion')\n",
    "male_list.remove('kimo')\n",
    "male_list.remove('kimoni')\n",
    "male_list.remove('jean')\n",
    "male_list.remove('mazon')\n",
    "male_list.remove('omere')\n",
    "male_list.remove('omero')\n",
    "male_list.remove('omer')\n",
    "male_list.remove('montgomery')\n",
    "male_list.remove('iver')\n",
    "male_list.remove('cedar')\n",
    "male_list.remove('onni')\n",
    "male_list.remove('seif')\n",
    "male_list.remove('chan')\n",
    "male_list.remove('chance')\n",
    "male_list.remove('chanse')\n",
    "male_list.remove('roni')\n",
    "male_list.remove('ronith')\n",
    "male_list.remove('ronit')\n",
    "male_list.remove('moroni')\n",
    "male_list.remove('geronimo')\n",
    "male_list.remove('ronin')\n",
    "male_list.remove('roniel')\n",
    "male_list.remove('jeronimo')\n",
    "male_list.remove('asher')\n",
    "male_list.remove('ashe')                                      \n",
    "male_list.remove('tate')\n",
    "male_list.remove('tatem')\n",
    "male_list.remove('chaos')\n",
    "male_list.remove('packer')\n",
    "male_list.remove('jess')\n",
    "male_list.remove('jessiah')\n",
    "male_list.remove('jessejames')\n",
    "male_list.remove('jessi')\n",
    "male_list.remove('jessey')\n",
    "male_list.remove('jessen')\n",
    "male_list.remove('jesse')\n",
    "male_list.remove('jessup')\n",
    "male_list.remove('jessee')\n",
    "male_list.remove('jessiel')\n",
    "male_list.remove('jessie')\n",
    "male_list.remove('jessy')\n",
    "male_list.remove('rolen')\n",
    "male_list.remove('olen')\n",
    "male_list.remove('eshin')\n",
    "male_list.remove('shine')\n",
    "male_list.remove('harden')\n",
    "male_list.remove('carden')\n",
    "male_list.remove('arden')\n",
    "male_list.remove('karden')\n",
    "male_list.remove('natalie')\n",
    "male_list.remove('vitali')\n",
    "male_list.remove('talib')\n",
    "male_list.remove('talin')\n",
    "male_list.remove('neftali')\n",
    "male_list.remove('vitaliy')\n",
    "male_list.remove('talion')\n",
    "male_list.remove('taliesin')\n",
    "male_list.remove('naftali')\n",
    "male_list.remove('stalin')\n",
    "male_list.remove('talik')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating function to help me rinse out the length 2 and length 3 names\n",
    "\n",
    "**by_size() - would help me select out **all** the words of that length and put them into a list**\n",
    "\n",
    "**get_rid() - would remove them from the list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_size(words, size):\n",
    "    return [word for word in words if len(str(word)) == size]\n",
    "\n",
    "def get_rid(orig_list, remove_list):\n",
    "    return [x for x in orig_list if x not in remove_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_2 = by_size(male_list,2)\n",
    "male_3 = by_size(male_list,3)\n",
    "\n",
    "female_2 = by_size(female_list,2)\n",
    "female_3 = by_size(female_list,3)\n",
    "\n",
    "male_list = get_rid(male_list, male_2)\n",
    "male_list = get_rid(male_list, male_3)\n",
    "\n",
    "female_list = get_rid(female_list, female_2)\n",
    "female_list = get_rid(female_list, female_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My list of words/names that I think would help identify a gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feminine_words = [\"girl\", \"princess\", \"wifey\", \"woman\", \"queen\", \"mom\", \"goddess\", \"gurl\", \"lady\", \"chic\", \"cutie\", \"miss\", \"kitty\", \"pam\", \"mrs\", \"mei\",\"jess\"]\n",
    "\n",
    "masculine_words = [\"dude\", \"prince\", \"handsome\", \"strong\", \"guy\", \"boy\", \"kid\", \"king\", \"stone\", \"rock\", \"rex\", \"hammer\", \"man\", \"brick\", \"warrior\", \"bwoy\", \"god\", \"mr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding the ^ list to our male/female list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_list.extend(masculine_words)\n",
    "female_list.extend(feminine_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sets make the list unique without repeating elements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_list = list(set(male_list))\n",
    "female_list = list(set(female_list))\n",
    "\n",
    "print('male:   ',len(male_list))\n",
    "print('female: ',len(female_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unworthy names\n",
    "\n",
    "**Removing non-male names from the male list only and unworthy names from both list**\n",
    "\n",
    "This is because the algorithm checks the male list first so whatever isn't in the male list would automatically go to the female list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = [x for x in male_list if x in female_list] # this allowed me to see what names were in both list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**names that I deemed should not be in both list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_they_both_should_not_have = ['aspen','prestyn','brantleigh','itzae','dakota','prabhjot','azul','peyton','xian','ivory','stone','neko','breckyn','tayte','kani','regan','bryn','royalty','sylvan','kayse','jourdyn','zixuan','musiq','landy','tylee','azeriah','iran','silver','berklee', 'pistol','brighten','emmery''kyler','zephyr','kemper','simcha','blessing','harlen','tobin','bridger','ares','avari','raylen','cyncere','oakland','dayton','waylon','majestic','wynter','greer','temple','esley','britten', 'kaelen','zeppelin','aman','harper','neriah','nakia','rebel','hope','zamari','demoni','jewell','masiah',\n",
    "'shiya',\n",
    "'romy',\n",
    "'callen',\n",
    "'seneca',\n",
    "'ryley',\n",
    "'jory', 'erioluwa',\n",
    " 'irish','kambryn',\n",
    " 'july',\n",
    " 'reegan',\n",
    " 'presley',\n",
    " 'peyten',\n",
    " 'camrynn','jakari',\n",
    " 'dalyn',\n",
    " 'graycin','zaiah',\n",
    " 'hunter',\n",
    " 'nasiah',\n",
    " 'elham',\n",
    " 'kemoni', 'reagan',\n",
    " 'torrin',\n",
    " 'brodie',\n",
    " 'oakland',\n",
    " 'cyncere',\n",
    " 'dayton',\n",
    " 'ares',\n",
    " 'raylen',\n",
    " 'avari',\n",
    " 'westley',\n",
    " 'reynolds','arlin',\n",
    " 'carrington',\n",
    " 'atley',\n",
    " 'emmerson','jennings',\n",
    " 'mayar',\n",
    " 'carsten',\n",
    " 'cooper',\n",
    " 'malone',\n",
    " 'rune',\n",
    " 'amaya',\n",
    " 'hurley',\n",
    " 'ziyi',\n",
    " 'dhani',\n",
    " 'larsen',\n",
    " 'karsyn','paiton',\n",
    " 'abriel',\n",
    " 'amery', 'cairo','daylin',\n",
    " 'holden',\n",
    " 'ilhan',\n",
    " 'braylyn',\n",
    " 'bless',\n",
    " 'kyrin',\n",
    " 'bralynn',\n",
    " 'mylin',\n",
    " 'bleu','kenzie',\n",
    " 'sari',\n",
    " 'burke','braelynn', 'seeley',\n",
    " 'tamari',\n",
    " 'carlisle','lawsyn',\n",
    " 'teddy',\n",
    " 'roan',\n",
    " 'mylan',\n",
    " 'carsen',\n",
    " 'rilyn','darby','vale',\n",
    " 'ashtin',\n",
    " 'amadi',\n",
    " 'briar','kymari',\n",
    " 'abisai',\n",
    " 'kamarie','auri',\n",
    " 'roux',\n",
    " 'shah',\n",
    " 'espn',\n",
    " 'kamori',\n",
    " 'corbin',\n",
    " 'reese',\n",
    " 'lincoln','emrys',\n",
    " 'keatyn',\n",
    " 'blayne',\n",
    " 'amoni',\n",
    " 'aaliyah','masiyah',\n",
    " 'janari',\n",
    " 'deniz','tashi','brantley',\n",
    " 'eriel',\n",
    " 'hazen',\n",
    " 'meron',\n",
    " 'halen',\n",
    " 'ireland',\n",
    " 'daegan', 'mena',\n",
    " 'emerald',\n",
    " 'hampton',\n",
    " 'chevy',\n",
    " 'brittan','archer',\n",
    " 'price', 'findlay',\n",
    " 'karsyn',\n",
    " 'brighten',\n",
    " 'haidyn',\n",
    " 'kamori',\n",
    " 'anthem',\n",
    " 'kymari',\n",
    " 'zephaniah',\n",
    " 'roux',\n",
    " 'ireoluwa',\n",
    " 'fenix','jasiah', 'bryer',\n",
    " 'zenith','jihan',\n",
    " 'zihan',\n",
    " 'devan','kendal','naveen','rumi','senna','denym','journey',\n",
    " 'colby',\n",
    " 'damani','uriel',\n",
    " 'jaxsyn',\n",
    " 'sina', 'eastyn',\n",
    " 'valen',\n",
    " 'ayomide',\n",
    " 'jazz',\n",
    " 'dallas','ziyon',\n",
    " 'jailyn',\n",
    " 'zaya',\n",
    " 'rosario','wrigley',\n",
    " 'mykel',\n",
    " 'mica',\n",
    " 'armanii', 'tylin','teigen',\n",
    " 'harper','oluwanifemi','zyan', 'bowie',\n",
    " 'amori','brogan',\n",
    " 'beren',\n",
    " 'prestyn',\n",
    " 'phenix',\n",
    " 'brylen',\n",
    " 'yiran',\n",
    " 'elli','lanier',\n",
    " 'kiernan','auri','amiel','mckay',\n",
    " 'braxton',\n",
    " 'kayse',\n",
    " 'kodie',\n",
    " 'breckin',\n",
    " 'kadyn',\n",
    " 'khoi','maximus', 'rylan', 'laiken',\n",
    " 'amour',\n",
    " 'deniz',\n",
    " 'yael',\n",
    " 'keoni',\n",
    " 'auden',\n",
    " 'taylin',\n",
    " 'legacy','atley','nael','loxley','cade','zyair',\n",
    " 'damoni',\n",
    " 'mercer','shayden','audi',\n",
    " 'ryleigh','keiran',\n",
    " 'christin',\n",
    " 'kensley',\n",
    " 'tamar',\n",
    " 'diem',\n",
    " 'kelley','elison',\n",
    " 'amzi',\n",
    " 'jansen',\n",
    " 'larson','kenley',\n",
    " 'kemper',\n",
    " 'kamsiyochukwu',\n",
    " 'kirby',\n",
    " 'berklee','kyndel',\n",
    " 'jaylyn',\n",
    " 'finnlee',\n",
    " 'basil',\n",
    " 'rana',\n",
    " 'kolbee',\n",
    " 'declyn','kenlee',\n",
    " 'kessler',\n",
    " 'ziyi',\n",
    " 'quin','merrick',\n",
    " 'embry',\n",
    " 'neri',\n",
    " 'kaydin',\n",
    " 'paysen',\n",
    " 'kaeden',\n",
    " 'brylin',\n",
    " 'rhyder',\n",
    " 'dhani','egypt',\n",
    " 'tanay',\n",
    " 'codi','hero',\n",
    " 'kamaree',\n",
    " 'kacee',\n",
    " 'temiloluwa',\n",
    " 'anay',\n",
    " 'reid',\n",
    " 'jailen',\n",
    " 'bodie',\n",
    " 'amor',\n",
    " 'abijah',\n",
    " 'yacine','garner','azel',\n",
    " 'bryar',\n",
    " 'ward',\n",
    " 'kolby',\n",
    " 'colton','kinsey','nile','zuri','jalin', 'sakari',\n",
    " 'rakhi',\n",
    " 'camdyn',\n",
    " 'marlo',\n",
    " 'deylin',\n",
    " 'ezra',\n",
    " 'darian',\n",
    " 'averie',\n",
    " 'koren',\n",
    " 'rylie',\n",
    " 'carsen',\n",
    " 'kieran','everly', 'smith',\n",
    " 'kohen','saia',\n",
    " 'golden',\n",
    " 'shae',\n",
    " 'landen',\n",
    " 'akira',\n",
    " 'kylenn',\n",
    " 'marion',\n",
    " 'rudi',\n",
    " 'dyllan',\n",
    " 'aarya',\n",
    " 'marvelous',\n",
    " 'anari',\n",
    " 'deylin',\n",
    " 'safi',\n",
    " 'peace',\n",
    " 'ezri',\n",
    " 'terran',\n",
    " 'chaise',\n",
    " 'uriyah','elisha',\n",
    " 'damani',\n",
    " 'jacy',\n",
    " 'jaxon',\n",
    " 'kena',\n",
    " 'jersey',\n",
    " 'jaylen',\n",
    " 'kaedyn','arlyn',\n",
    " 'kayton',\n",
    " 'lamar','ifeoluwa',\n",
    " 'graisyn',\n",
    " 'kinsey',\n",
    " 'ryleigh',\n",
    " 'kanai',\n",
    " 'jonnie',\n",
    " 'gunnar',\n",
    " 'grey',\n",
    " 'elim',\n",
    " 'hudsyn',\n",
    " 'mina',\n",
    " 'cire', 'sahib',\n",
    " 'cadence',\n",
    " 'bawi',\n",
    " 'erian',\n",
    " 'maddix',\n",
    " 'jaidynn',\n",
    " 'autry',\n",
    " 'avri',\n",
    " 'blythe',\n",
    " 'payton',\n",
    " 'jakari',\n",
    " 'amazing',\n",
    " 'landy',\n",
    " 'kyan',\n",
    " 'danyel',\n",
    " 'daegan',\n",
    " 'korbyn',\n",
    " 'jahan',\n",
    " 'oluwasemilore',\n",
    " 'peyten',\n",
    " 'merrick',\n",
    " 'bryley',\n",
    " 'haden',\n",
    " 'mccartney',\n",
    " 'sani',\n",
    " 'munachiso',\n",
    " 'jensyn','waylon',\n",
    " 'calvary',\n",
    " 'galaxy',\n",
    " 'nakia',\n",
    " 'graecyn',\n",
    " 'camryn',\n",
    " 'sivan','araya',\n",
    " 'adyson', 'mena',\n",
    " 'dalyn','mecca',\n",
    " 'mana',\n",
    " 'bryn',\n",
    " 'shyne',\n",
    " 'havyn','imari',\n",
    " 'micaiah',\n",
    " 'cobie',\n",
    " 'torrance',\n",
    " 'jayceon',\n",
    " 'steele',\n",
    " 'kaylen',\n",
    " 'desi',\n",
    " 'parish',\n",
    " 'kirin',\n",
    " 'khristian',\n",
    " 'hargun',\n",
    " 'landyn',\n",
    " 'farris',\n",
    " 'nael',\n",
    " 'mckay','tilden',\n",
    " 'nehemiah',\n",
    " 'lyriq','evin',\n",
    " 'amit','kamarii','wyatt',\n",
    " 'walker','kamryn','arlie',\n",
    " 'aziel',\n",
    " 'reagan',\n",
    " 'torrin','diamond',\n",
    " 'zabdi',\n",
    " 'marcel',\n",
    " 'caydence',\n",
    " 'joss',\n",
    " 'kaycee',\n",
    " 'fletcher','tylee',\n",
    " 'cannon',\n",
    " 'masiah',\n",
    " 'ariyan',\n",
    " 'harbor',\n",
    " 'kayan',\n",
    " 'braelin','stone','konner', 'drue',\n",
    " 'loren',\n",
    " 'pierce', 'derin',\n",
    " 'harlem',\n",
    " 'eastyn','marlyn',\n",
    " 'camauri',\n",
    " 'finesse',\n",
    " 'kyndall',\n",
    " 'kiernan',\n",
    " 'larson',\n",
    " 'devon',\n",
    " 'peyton',\n",
    " 'ziyan','jamesyn',\n",
    " 'camrynn',\n",
    " 'amara',\n",
    " 'samar',\n",
    " 'kylin','loran',\n",
    " 'arrington',\n",
    " 'darrian',\n",
    " 'kaydence',\n",
    " 'rogue','satya','avery',\n",
    " 'payden',\n",
    " 'jaelin',\n",
    " 'cyncere',\n",
    " 'azure',\n",
    " 'luna',\n",
    " 'reign','bridger',\n",
    " 'meerab',\n",
    " 'bliss','deniz','aseel',\n",
    " 'mason',\n",
    " 'dezi',\n",
    " 'macklyn','zoel',\n",
    " 'tennyson',\n",
    " 'khoi','shai',\n",
    " 'kiran',\n",
    " 'daylin',\n",
    " 'irie',\n",
    " 'ajai',\n",
    " 'teryn',\n",
    " 'wilder',\n",
    " 'oaklee',\n",
    " 'jalen',\n",
    " 'yancy','avis', 'qamar',\n",
    " 'jayse',\n",
    " 'cherokee', 'harbour',\n",
    " 'kolbi','ngun',\n",
    " 'ilhan',\n",
    " 'nijah',\n",
    " 'dior','jael',\n",
    " 'thai',\n",
    " 'dymond',\n",
    " 'kanon',\n",
    " 'eisa', 'kharter',\n",
    " 'carrington',\n",
    " 'ezariah',\n",
    " 'dmani',\n",
    " 'avari','maddox',\n",
    " 'vega',\n",
    " 'westyn','andersen',\n",
    " 'dallis',\n",
    " 'armoni', 'maddux',\n",
    " 'zamari',\n",
    " 'rhylen',\n",
    " 'aedyn',\n",
    " 'landon',\n",
    " 'lenyx','anmol',\n",
    " 'palmer',\n",
    " 'diem',\n",
    " 'foster',\n",
    " 'caelan',\n",
    " 'remy',\n",
    " 'dorian',\n",
    " 'rhyan','maesyn',\n",
    " 'tylin',\n",
    " 'keilani',\n",
    " 'oluwatobi',\n",
    " 'olamide',\n",
    " 'tallyn',\n",
    " 'north','hadyn','oluwadarasimi',\n",
    " 'marlee',\n",
    " 'keylen',\n",
    " 'moxley',\n",
    " 'kennon',\n",
    " 'chesney',\n",
    " 'elan','kellen','faelan',\n",
    " 'treasure',\n",
    " 'schuyler',\n",
    " 'cobi',\n",
    " 'leigh','nori',\n",
    " 'sylvan',\n",
    " 'kaelyn',\n",
    " 'zephyr',\n",
    " 'indiana',\n",
    " 'zyon',\n",
    " 'brodie',\n",
    " 'bexley',\n",
    " 'karlin',\n",
    " 'paris',\n",
    " 'musiq',\n",
    " 'payten',\n",
    " 'harvest','haedyn',\n",
    " 'renn',\n",
    " 'luca',\n",
    " 'bralyn',\n",
    " 'delaney',\n",
    " 'maysen',\n",
    " 'cheyenne','bentlie',\n",
    " 'jupiter',\n",
    " 'luke',\n",
    " 'arlen',\n",
    " 'alva',\n",
    " 'rogan',\n",
    " 'azriel',\n",
    " 'hanley',\n",
    " 'kendal',\n",
    " 'rian',\n",
    " 'gaige',\n",
    " 'saige',\n",
    " 'collyn',\n",
    " 'abbott',\n",
    " 'dasani', 'haidyn','erioluwa',\n",
    " 'asaiah']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**names that I deemed should not be in the males list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_names = ['shannon','jamey','zoey','tracy','luna','nour','layla','casey','lucy','sofia','courtney','merrill','justine','christin','jolin','emily','ariel','lindsey','sena','blair','lynn','elin','jamie','eliana','kassidy','ciel', 'kristian', 'hannah', 'whitney','layla', 'olivia','blair','audrey', 'quinn','darcy','sofia','stella','lindsey','aria','ezra','rain','jules','hanna','carmen','brianna','melissa','andrea','abeer','cortney','kylie','audrey','nana','nelly','alice','gabriella','elin','artemis','joyce','charlotte','lynn','victoria','rayne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_name_set = set(names_they_both_should_not_have)\n",
    "female_name_set = set(female_names)\n",
    "\n",
    "bad_name_list = list(bad_name_set)\n",
    "female_nam = list(female_name_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_wo_bad_names = [x for x in male_list if x not in bad_name_list]           # removing the bad names from the male list\n",
    "\n",
    "female_wo_bad_names = [x for x in female_list if x not in bad_name_list]       # removing the bad names from the female list\n",
    "\n",
    "male_wo_female_and_bad = [x for x in male_wo_bad_names if x not in female_nam] # removing the female names from the male list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This process might take awhile (like an hour ish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_list = []\n",
    "\n",
    "for name in unknown_list:\n",
    "    if any(str(word) in name for word in male_wo_female_and_bad):\n",
    "        gender_list.append('male')\n",
    "    elif any(str(word) in name for word in female_wo_bad_names):\n",
    "        gender_list.append('female')\n",
    "    else:\n",
    "        gender_list.append('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data.loc[gender_data['gender'].eq('unknown'), 'gender'] = gender_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data.to_pickle('Supreme_genders_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_data = gender_data[gender_data.gender != 'unknown']\n",
    "\n",
    "gender_data.reset_index(drop=True, inplace = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
